{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNwt9bSG0hin"
   },
   "source": [
    "# Performing GPU Batch Prediction on Images with a PyTorch Model\n",
    "\n",
    "In this example, we will introduce how to use the Ray AIR {class}`BatchPredictor <ray.train.batch_predictor.BatchPredictor>` for **large-scale batch inference with multiple GPU workers.**\n",
    "\n",
    "In particular, we will:\n",
    "- Load Imagenette dataset from S3 bucket and create a ray dataset.\n",
    "- Load a pretrained ResNet model and build a checkpoint.\n",
    "- Define a preprocessor.\n",
    "- Construct a BatchPredictor with the checkpoint and preprocessor.\n",
    "- Do batch prediction on multiple GPUs.\n",
    "- Evaluate the predictions and save results to S3/local disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this example, you will need to install the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q \"ray[air]\" boto3 torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Imagenette](https://github.com/fastai/imagenette) is a subset of Imagenet with 10 classes. First, we use {meth}`ray.data.read_images <ray.data.read_images>` to load the validation set from S3. Since the dataset is already structured with directory names as the labels, we can use the {class}`Partitioning <ray.data.datasource.Partitioning>` API to automatically extract image labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "217255c5a2ba4ec5890f6f3667f5b429"
     ]
    },
    "id": "6i15qjnH0hin",
    "outputId": "c22aaba0-b33a-40f5-cf89-a70847098af2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.data.datasource.partitioning import Partitioning\n",
    "\n",
    "s3_uri = \"s3://anonymous@air-example-data-2/imagenette2/val/\"\n",
    "\n",
    "# The S3 directory structure is {s3_uri}/{class_id}/{*.JPEG}\n",
    "partitioning = Partitioning(\"dir\", field_names=[\"class\"], base_dir=s3_uri)\n",
    "\n",
    "ds = ray.data.read_images(\n",
    "    s3_uri, size=(256, 256), partitioning=partitioning, mode=\"RGB\"\n",
    ")\n",
    "ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.take(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTnynr1O0hio"
   },
   "source": [
    "As we can see, each example contains one image tensor of shape (256, 256, 3) and its label. Notice that the label for images are their corresponding directory names (e.g. n01728920). To find the indices of our model output that correspond to these names, we'll need to download a mapping from the s3 bucket (`imagenet_class_index.json`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qf6uTXPt0hio",
    "tags": [
     "hide-cell",
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# If you want to run the full example, please set this to False\n",
    "SMOKE_TEST = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "zWuhWsx50hio",
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# @title +\n",
    "if SMOKE_TEST:\n",
    "    ds = ds.limit(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aj-f1jrg0hio",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "\n",
    "# Download mapping file from S3\n",
    "s3 = boto3.client(\"s3\", config=Config(signature_version=UNSIGNED))\n",
    "s3.download_file(\n",
    "    \"air-example-data-2\",\n",
    "    \"imagenette2/imagenet_class_index.json\",\n",
    "    \"/tmp/imagenet_class_index.json\",\n",
    ")\n",
    "\n",
    "# Build mappings\n",
    "idx_to_class = json.load(open(\"/tmp/imagenet_class_index.json\", \"r\"))\n",
    "class_to_idx = {cls_name: int(index) for index, (cls_name, _) in idx_to_class.items()}\n",
    "idx_to_class_name = {int(index): text for index, (_, text) in idx_to_class.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KChQFIuB0hip"
   },
   "source": [
    "Next, let's define a preprocessor to crop and normalize images, as well as convert the class names to indices with the map that we just constructed. \n",
    "\n",
    "We'll first use a {class}`TorchVisionPreprocessor <ray.data.preprocessors.TorchVisionPreprocessor>` to crop and normalize the images. Then, we will implement a function to map labels the class name to the respective index. The above data preprocessing logic will be applied to the input dataset before feeding the data into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2jZzieus0hip",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from ray.data.preprocessors import BatchMapper, TorchVisionPreprocessor, Chain\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "def to_tensor(batch: np.ndarray) -> torch.Tensor:\n",
    "    tensor = torch.as_tensor(batch, dtype=torch.float)\n",
    "    # (B, H, W, C) -> (B, C, H, W)\n",
    "    tensor = tensor.permute(0, 3, 1, 2).contiguous()\n",
    "    # [0., 255.] -> [0., 1.]\n",
    "    tensor = tensor.div(255)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Lambda(to_tensor),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Accelerate image processing with batched transformations\n",
    "image_preprocessor = TorchVisionPreprocessor(\n",
    "    columns=[\"image\"], transform=transform, batched=True\n",
    ")\n",
    "\n",
    "# Map the image labels from strings to integer ids\n",
    "def map_labels(batch: np.ndarray) -> np.ndarray:\n",
    "    batch[\"label\"] = np.vectorize(class_to_idx.__getitem__)(batch[\"class\"])\n",
    "    return batch\n",
    "\n",
    "processed_ds = ds.map_batches(image_preprocessor).map_batches(map_labels, batch_format=\"numpy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jb4xtRAu0hip"
   },
   "source": [
    "## Distributed Inference\n",
    "\n",
    "As the last step, we will do inference with a {class}`~ray.train.torch.TorchPredictor`. By using Ray Datasets, we can distribute the inference workload across multiple workers and run prediction on multiple shards of data in parallel. You can find more details in [Using Predictors for Inference](air-predictors).\n",
    "\n",
    "For the demo, we'll directly load a pretrained ResNet model from `torchvision.models`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zb-xEyuw0hip"
   },
   "source": [
    "We specified several parameters in `map_batches`:\n",
    "- `feature_columns` specifies which columns are required for the model.\n",
    "- The columns in `keep_columns` will be returned together with the prediction results. For example, you can keep image labels for evaluation later.\n",
    "- `map_batches` uses CPUs for inference by default, please specify `num_gpus` if you want to use GPUs.\n",
    "- We specify an `ActorPoolStrategy` indicating how many workers we want to use for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BVh4fddm0hip",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from ray.train.batch_predictor import BatchPredictor\n",
    "from ray.train.torch import TorchPredictor\n",
    "\n",
    "# Load the pretrained resnet model and construct a TorchPredictor\n",
    "model = models.resnet152(pretrained=True)\n",
    "predictor = TorchPredictor(model)\n",
    "\n",
    "predictions = processed_ds.map_batches(predictor, \n",
    "                             compute=ray.data.ActorPoolStrategy(4, 4), \n",
    "                             batch_size=128, \n",
    "                             num_gpus=1,\n",
    "                             fn_kwargs={\"feature_columns\": [\"image\"], \"keep_columns\": [\"label\"]})\n",
    "\n",
    "predictions.cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n01NTzRu0hip"
   },
   "source": [
    "## Evaluating Prediction Accuracy\n",
    "\n",
    "Our `predictions` dataset contains a column of model output with key `\"predictions\"`, and all columns specified in `keep_columns`.\n",
    "\n",
    "In this example, the output of the ResNet model is a 1000-dimensional tensor containing the logits of each class. We'll measure accuracy with Top-1 and Top-5 accuracy.\n",
    "(Top-N accuracy: The percentage of predictions where the true label falls in the top N predicted classes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ds_AI7FW0hip",
    "outputId": "b17fcda6-7944-4403-e463-654c1c162189",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_matches(batch: pd.DataFrame) -> pd.DataFrame:\n",
    "    batch[\"top_5_pred\"] = batch[\"predictions\"].apply(lambda x: np.argsort(-x)[:5])\n",
    "    batch[\"top_5_pred_name\"] = batch[\"top_5_pred\"].map(\n",
    "        lambda x: [idx_to_class_name[idx] for idx in x]\n",
    "    )\n",
    "    batch[\"top_5_match\"] = batch.apply(lambda x: x[\"label\"] in x[\"top_5_pred\"], axis=1)\n",
    "    batch[\"top_1_match\"] = batch.apply(\n",
    "        lambda x: x[\"label\"] == x[\"top_5_pred\"][0], axis=1\n",
    "    )\n",
    "    return batch\n",
    "\n",
    "\n",
    "predictions = predictions.map_batches(calculate_matches, batch_format=\"pandas\")\n",
    "print(\"Top-1 accuracy: \", predictions.mean(on=\"top_1_match\"))\n",
    "print(\"Top-5 accuracy: \", predictions.mean(on=\"top_5_match\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bbjYeRuN0hiq",
    "outputId": "cb0dbb3f-d8ed-4ad5-c76d-c003a8928def",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "# Take an example from the model's prediction\n",
    "sample_image = ds.take(1)[0]\n",
    "sample_pred = predictions.take(1)[0]\n",
    "display(Image.fromarray(sample_image[\"image\"]))\n",
    "print(\"Top-1 Matched: \", sample_pred[\"top_1_match\"])\n",
    "print(\"Top-5 Predictions: \", sample_pred[\"top_5_pred_name\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmQjQT2b0hiq"
   },
   "source": [
    "## Save Prediction Results\n",
    "\n",
    "There are a few options for saving your prediction results:\n",
    "- You can call `ds.repartition(n)` to split your prediction results into n partitions, then n files will be created with `write_parquet()` later.\n",
    "- You can either store files to your local disk or S3 bucket by passing local path or S3 uri to `write_parquet()`.\n",
    "- Other output file formats are described here: [Ray Data Input/Output](https://docs.ray.io/en/latest/data/api/input_output.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cdlrHfNS0hiq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions.repartition(1).write_parquet(\"local://tmp/single_parquet\")\n",
    "# >>> /tmp/single_parquet/d757569dfb2845589b0ccbcb263e8cc3_000000.parquet\n",
    "\n",
    "predictions.repartition(3).write_parquet(\"local://tmp/multiple_parquet\")\n",
    "# >>> /tmp/multiple_parquet/2b529dc5d8eb45e5ad03e69fb7ad8bc0_000000.parquet\n",
    "# >>> /tmp/multiple_parquet/2b529dc5d8eb45e5ad03e69fb7ad8bc0_000001.parquet\n",
    "# >>> /tmp/multiple_parquet/2b529dc5d8eb45e5ad03e69fb7ad8bc0_000002.parquet\n",
    "\n",
    "# You can also save results to S3 by replacing local path to S3 URI\n",
    "# predictions.write_parquet(YOUR_S3_BUCKET_URI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a8c1140d108077f4faeb76b2438f85e4ed675f93d004359552883616a1acd54c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
